apiVersion: template.openshift.io/v1
kind: Template
metadata:
  annotations:
    description: Upstream vLLM ServingRuntime for KServe
    opendatahub.io/apiProtocol: REST
    opendatahub.io/modelServingSupport: '["single"]'
    tags: kserve,servingruntime
  labels:
    opendatahub.io/dashboard: "true"
    app.opendatahub.io/model-mesh: "false"
  name: vllm-openai-template
  namespace: redhat-ods-applications
objects:
- apiVersion: serving.kserve.io/v1alpha1
  kind: ServingRuntime
  metadata:
    annotations:
      opendatahub.io/recommended-accelerators: '["nvidia.com/gpu"]'
      openshift.io/display-name: Upstream vLLM ServingRuntime for KServe
    labels:
      opendatahub.io/dashboard: "true"
    name: vllm-openai-runtime
  spec:
    annotations:
      prometheus.io/path: /metrics
      prometheus.io/port: "8080"
    multiModel: false
    supportedModelFormats:
    - name: vllm
      autoSelect: true
    containers:
    - name: kserve-container
      image: docker.io/vllm/vllm-openai:latest
      #image: docker.io/kserve/vllmserver:latest
      workingDir: /root
      command:
      - bash
      - "-c"
      - |
        GPU_COUNT="$(echo -n $NVIDIA_VISIBLE_DEVICES | awk -F, '{ print NF }')"
        if [ -z "$GPU_COUNT" ]; then
          GPU_COUNT=1
        fi
        echo "number of gpus=$GPU_COUNT"
        echo "args=$@"
        exec python3 -m vllm.entrypoints.openai.api_server \
          --port 8080 \
          --model /mnt/models \
          --tensor-parallel-size $GPU_COUNT $@
      ports:
      - containerPort: 8080
        protocol: TCP
      env:
      - name: HOME # needed because we need to write to $HOME/.cache
        value: /root
      - name: PYTHONPATH
        value: /workspace
      volumeMounts:
      - name: home
        mountPath: /root
      livenessProbe:
        httpGet:
          path: /version
          port: 8080
        initialDelaySeconds: 240
      readinessProbe:
        httpGet:
          path: /version
          port: 8080
        initialDelaySeconds: 200
      startupProbe:
        httpGet:
          path: /version
          port: 8080
        failureThreshold: 60
        periodSeconds: 10
    volumes:
    - name: home
      emptyDir: {}
    tolerations:
      - key: nvidia.com/gpu
        value: "True"
        effect: NoSchedule